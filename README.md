# NLP Complaint Classification Pipeline

A production-grade binary text classification pipeline built using **strict Test-Driven Development (TDD)** methodology. This project demonstrates ML engineering best practices including leakage prevention, reproducibility, clean architecture, and comprehensive testing.

## ğŸ¯ Problem Statement

Binary classification of customer complaints to distinguish between negative complaints (class 0) and positive feedback (class 1). The pipeline processes raw text through preprocessing, feature extraction, model training, and evaluation with explicit focus on preventing data leakage and ensuring reproducible results.

## âœ¨ Key Features

### Engineering Excellence
- **Strict TDD Methodology**: 9 complete RED â†’ GREEN â†’ REFACTOR cycles
- **253 Comprehensive Tests**: 244 unit tests + 9 integration tests (100% pass rate)
- **Data Leakage Prevention**: Explicit fit/transform separation with comprehensive testing
- **Deterministic Pipeline**: Fixed random seeds throughout for reproducibility
- **Type-Hinted APIs**: Modern Python type hints on all public functions
- **Clean Architecture**: Single-responsibility modules with clear separation of concerns

### ML Capabilities
- **Dual Model Support**: TF-IDF + Logistic Regression (default) or BERT-based classification
- **Baseline-First Approach**: Simple, interpretable models before complexity
- **Comprehensive Metrics**: Accuracy, Precision, Recall, F1, ROC-AUC
- **Stratified Splitting**: Maintains class balance in train/test sets
- **Backward Compatible**: BERT integration doesn't break TF-IDF pipeline

## ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/SourabhaKK/nlp-complaint-classification-pipeline.git
cd nlp-complaint-classification-pipeline

# Install dependencies
pip install -r requirements.txt
```

**Requirements:**
- Python 3.10+
- pandas >= 2.0.0
- numpy >= 1.24.0
- scikit-learn >= 1.3.0
- datasets >= 2.14.0
- pytest >= 7.4.0

## ğŸš€ Usage

### TF-IDF Pipeline (Default)

```python
from src.pipeline import run_pipeline

# Run complete pipeline with TF-IDF + Logistic Regression
result = run_pipeline(
    data_source="huggingface",
    test_size=0.2,
    random_state=42
)

# Access trained model and metrics
model = result["model"]
metrics = result["metrics"]

print(f"Accuracy: {metrics['accuracy']:.3f}")
print(f"F1 Score: {metrics['f1']:.3f}")
```

### BERT Pipeline

```python
from src.pipeline import run_pipeline

# Run pipeline with BERT-based classification
result = run_pipeline(
    data_source="huggingface",
    test_size=0.2,
    random_state=42,
    model_type="bert"  # Switch to BERT
)

# BERT model and metrics
bert_model = result["model"]
bert_metrics = result["metrics"]
```

### Individual Components

```python
from src.text_preprocessing import preprocess_text
from src.vectorizer import fit_vectorizer, transform_texts
from src.model_training import train_model

# Preprocess text
clean_text = preprocess_text("Hello! This is a test.")
# Output: "hello this is a test"

# Fit TF-IDF vectorizer (training data only)
vectorizer = fit_vectorizer(train_texts)

# Transform texts (both train and test)
X_train = transform_texts(vectorizer, train_texts)
X_test = transform_texts(vectorizer, test_texts)

# Train model
model = train_model(X_train, y_train, random_state=42)
```

## ğŸ“ Project Structure

```
nlp-complaint-classification-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py          # Hugging Face dataset loader
â”‚   â”œâ”€â”€ data_validation.py      # DataFrame schema validation
â”‚   â”œâ”€â”€ data_splits.py          # Label validation & stratified splitting
â”‚   â”œâ”€â”€ text_preprocessing.py   # Deterministic text cleaning
â”‚   â”œâ”€â”€ vectorizer.py           # TF-IDF with leakage prevention
â”‚   â”œâ”€â”€ model_training.py       # Baseline classifier training
â”‚   â”œâ”€â”€ prediction.py           # Prediction interface
â”‚   â”œâ”€â”€ evaluation.py           # Classification metrics
â”‚   â”œâ”€â”€ pipeline.py             # End-to-end orchestration
â”‚   â””â”€â”€ bert/                   # BERT integration (optional)
â”‚       â”œâ”€â”€ tokenizer.py
â”‚       â”œâ”€â”€ model.py
â”‚       â”œâ”€â”€ trainer.py
â”‚       â””â”€â”€ predictor.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_loader.py     # 23 tests
â”‚   â”œâ”€â”€ test_data_validation.py # 16 tests
â”‚   â”œâ”€â”€ test_data_splits.py     # 23 tests
â”‚   â”œâ”€â”€ test_text_preprocessing.py  # 42 tests
â”‚   â”œâ”€â”€ test_vectorizer.py      # 30 tests
â”‚   â”œâ”€â”€ test_model_training.py  # 24 tests
â”‚   â”œâ”€â”€ test_prediction.py      # 21 tests
â”‚   â”œâ”€â”€ test_evaluation.py      # 28 tests
â”‚   â”œâ”€â”€ test_pipeline.py        # 22 tests
â”‚   â”œâ”€â”€ test_integration.py     # 9 integration tests
â”‚   â””â”€â”€ bert/                   # 50 BERT tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test module
pytest tests/test_pipeline.py

# Run integration tests only
pytest tests/test_integration.py -v
```

**Test Coverage:**
- **253 total tests** (100% pass rate)
- **Unit tests**: 244 tests covering all modules
- **Integration tests**: 9 end-to-end pipeline tests
- **Test types**: Functionality, edge cases, input validation, determinism, leakage prevention

## ğŸ—ï¸ Design Decisions

### 1. **TDD Methodology**
- **Why**: Ensures correctness, prevents regressions, documents expected behavior
- **How**: 9 complete RED â†’ GREEN â†’ REFACTOR cycles with numbered commits

### 2. **Leakage Prevention**
- **Why**: Critical for valid model evaluation
- **How**: Vectorizer fit ONLY on training data, explicit tests for leakage scenarios

### 3. **Baseline-First Approach**
- **Why**: Simple models are interpretable, fast, and establish performance floor
- **How**: Logistic Regression as default before adding BERT complexity

### 4. **Modular Architecture**
- **Why**: Separation of concerns, testability, maintainability
- **How**: Each component in separate file with single responsibility

### 5. **Deterministic Pipeline**
- **Why**: Reproducible results for debugging and validation
- **How**: Fixed `random_state` throughout, deterministic preprocessing

### 6. **Optional BERT Integration**
- **Why**: Demonstrates extensibility without breaking existing functionality
- **How**: `model_type` parameter with backward-compatible default

## âš ï¸ Limitations

### Current Scope
- **Binary classification only**: Supports 2 classes (complaint vs. positive feedback)
- **Lightweight BERT**: Demonstration implementation, not production-scale transformer
- **No hyperparameter tuning**: Focus on engineering patterns over model optimization
- **No deployment infrastructure**: Pipeline code only, no REST API or containerization
- **Synthetic integration tests**: Real pipeline logic but mocked data loader for CI/CD

### Production Considerations
For production deployment, consider adding:
- Model versioning and serialization
- Logging and monitoring
- A/B testing framework
- Data drift detection
- Automated retraining pipeline
- REST API with FastAPI
- Docker containerization
- Load testing and performance optimization

## ğŸ“Š TDD Cycle History

| Cycle | Component | Tests | Status |
|-------|-----------|-------|--------|
| 1 | Data Validation | 16 | âœ… Complete |
| 1.5 | Dataset Loader | 23 | âœ… Complete |
| 2 | Label Validation & Splits | 23 | âœ… Complete |
| 3 | Text Preprocessing | 42 | âœ… Complete |
| 4 | TF-IDF Vectorization | 30 | âœ… Complete |
| 5 | Model Training | 24 | âœ… Complete |
| 6 | Prediction Interface | 21 | âœ… Complete |
| 7 | Evaluation Metrics | 28 | âœ… Complete |
| 8 | Pipeline Orchestration | 22 | âœ… Complete |
| 9 | BERT Integration | 56 | âœ… Complete |

## ğŸ“ What This Project Demonstrates

### ML Engineering Skills
- âœ… Data leakage prevention and validation
- âœ… Reproducible ML pipelines
- âœ… Proper train/test separation
- âœ… Comprehensive evaluation metrics
- âœ… Baseline model establishment

### Software Engineering Skills
- âœ… Test-Driven Development (TDD)
- âœ… Clean architecture and SOLID principles
- âœ… Type hints and modern Python practices
- âœ… Git workflow with semantic commits
- âœ… Documentation and code clarity

### Production Readiness
- âœ… Input validation and error handling
- âœ… Deterministic behavior
- âœ… Extensible design (easy to add new models)
- âœ… CI/CD compatible (fast, isolated tests)
- âœ… Honest assessment of limitations

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ‘¤ Author

**Sourabha Kallapur**
- GitHub: [@SourabhaKK](https://github.com/SourabhaKK)
- Email: sourabha.kallapurk@gmail.com

---

**Built with strict TDD discipline â€¢ 253 tests â€¢ 100% pass rate â€¢ Production-grade ML engineering**
